{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运用NLTK包来对文本进行基本操作\n",
    "1.通过 pip install nltk 安装python nltk包\n",
    "2.python的NLTK是一个开源的项目，全称natural language toolkit,在项目中包含了Python模块，数据集和教程，主要用于NLP的研究和开发。\n",
    "3.其中基本的内置函数有：\n",
    "4.关键词搜索：concordance 查找词出现位置\n",
    "5.相关词索引：similar 查找哪些词出现在相似的上下文中\n",
    "6.相同上下文查找：common_contexts\n",
    "7.检测词出现位置：dispersion_plot\n",
    "8.获取长度：len()\n",
    "9.词表排序：sorted()\n",
    "10.扩充词表：append()\n",
    "11.索引列表：index()（链表从0开始计数）（索引过大会造成超界）\n",
    "12.切片操作：list[a:b] 获得a到b之间的数组\n",
    "13.#在定义变量是切记不能与保留字冲突#\n",
    "14.字符串可以进行乘法和加法操作，但不能进行减法和除法操作\n",
    "15.使用FreqDist可以生成字典\n",
    "16.可以通过循环和特征语句来根据特征选择词，也可以通过多个特征选择词\n",
    "17.在ipython中可通过Tab+Shift查看自带的函数命令\n",
    "18.通过数值比较运算符和词汇比较运算发可以起到决策和控制的作用\n",
    "\n",
    "\n",
    "# 自然语言处理在实际应用中的例子：\n",
    "\n",
    "## 词意消歧\n",
    "意义：分析上下文中的词被赋予的是哪个意思\n",
    "特征：需要使用上下文并利用相邻词汇的相近含义\n",
    "方法1：基于词典的词义消歧方法\n",
    "    基于词典的词义消歧始于利用词典中词义(亦称“义项”)解释或定义来指导歧义词的词义判断目。该方法简单易行，只需计算歧义词的各个词义在词典中的定义与歧义词上下文词语的定义之间的覆盖度，选择覆盖度最大的作为正确的词义。词典对词义的定义语句力求简单明了，这样使得很多歧义词的各个词义解释与上下文词语的覆盖度几乎为零，造成消歧失败。\n",
    "方法2：基于语料库的词义消歧\n",
    "    基于语料库的统计方法通过计算给定文本中词汇语义在多义词上下文中的概率权重，选择具有最大概率权重的语义作为最佳结果输出，该方法根据训练语料事先是否经过人工标注又可以分为两类：有指导的词义消歧和无指导的的词义消歧幽。\n",
    "\n",
    "## 指代消解\n",
    "意义：检测动词的主语和宾语\n",
    "例如：The thieves stole the paintings.They were subsequently sold(caught/found)\n",
    "存在歧义寻找they的先行词：\n",
    "    指代消解：解决确定代词或名词短语指的是什么\n",
    "    语义角色标注：确定名词短语如何与动词相关联\n",
    "\n",
    "## 语义角色标注和语义依存分析\n",
    "引用自：https://www.ltp-cloud.com/intro/ 更多相关语言分析可从上面找到\n",
    "意义：语义角色标注 (Semantic Role Labeling, SRL) 是一种浅层的语义分析技术，标注句子中某些短语为给定谓词的论元 (语义角色) ，如施事、受事、时间和地点等。其能够对问答系统、信息抽取和机器翻译等应用产生推动作用。 \n",
    "核心的语义角色为 A0-5 六种，A0 通常表示动作的施事，A1通常表示动作的影响等，A2-5 根据谓语动词不同会有不同的语义含义。其余的15个语义角色为附加语义角色，如LOC 表示地点，TMP 表示时间等。附加语义角色列表如下：\n",
    "标记\t说明\n",
    "ADV\tadverbial, default tag ( 附加的，默认标记 )\n",
    "BNE\tbeneﬁciary ( 受益人 )\n",
    "CND\tcondition ( 条件 )\n",
    "DIR\tdirection ( 方向 )\n",
    "DGR\tdegree ( 程度 )\n",
    "EXT\textent ( 扩展 )\n",
    "FRQ\tfrequency ( 频率 )\n",
    "LOC\tlocative ( 地点 )\n",
    "MNR\tmanner ( 方式 )\n",
    "PRP\tpurpose or reason ( 目的或原因 )\n",
    "TMP\ttemporal ( 时间 )\n",
    "TPC\ttopic ( 主题 )\n",
    "CRD\tcoordinated arguments ( 并列参数 )\n",
    "PRD\tpredicate ( 谓语动词 )\n",
    "PSR\tpossessor ( 持有者 )\n",
    "PSE\tpossessee ( 被持有 )\n",
    "\n",
    "意义：语义依存分析 (Semantic Dependency Parsing, SDP)，分析句子各个语言单位之间的语义关联，并将语义关联以依存结构呈现。 使用语义依存刻画句子语义，好处在于不需要去抽象词汇本身，而是通过词汇所承受的语义框架来描述该词汇，而论元的数目相对词汇来说数量总是少了很多的。语义依存分析目标是跨越句子表层句法结构的束缚，直接获取深层的语义信息。\n",
    "语义依存分析不受句法结构的影响，将具有直接语义关联的语言单元直接连接依存弧并标记上相应的语义关系。这也是语义依存分析与句法依存分析的重要区别。\n",
    "语义依存与语义角色标注之间也存在关联，语义角色标注只关注句子主要谓词的论元及谓词与论元之间的关系，而语义依存不仅关注谓词与论元的关系，还关注谓词与谓词之间、论元与论元之间、论元内部的语义关系。语义依存对句子语义信息的刻画更加完整全面。\n",
    "\n",
    "语义依存关系分为三类，分别是主要语义角色，每一种语义角色对应存在一个嵌套关系和反关系；事件关系，描述两个事件间的关系；语义依附标记，标记说话者语气等依附性信息。\n",
    "\n",
    "关系类型\tTag\tDescription\tExample\n",
    "施事关系\tAgt\tAgent\t我送她一束花 (我 <-- 送)\n",
    "当事关系\tExp\tExperiencer\t我跑得快 (跑 --> 我)\n",
    "感事关系\tAft\tAffection\t我思念家乡 (思念 --> 我)\n",
    "领事关系\tPoss\tPossessor\t他有一本好读 (他 <-- 有)\n",
    "受事关系\tPat\tPatient\t他打了小明 (打 --> 小明)\n",
    "客事关系\tCont\tContent\t他听到鞭炮声 (听 --> 鞭炮声)\n",
    "成事关系\tProd\tProduct\t他写了本小说 (写 --> 小说)\n",
    "源事关系\tOrig\tOrigin\t我军缴获敌人四辆坦克 (缴获 --> 坦克)\n",
    "涉事关系\tDatv\tDative\t他告诉我个秘密 ( 告诉 --> 我 )\n",
    "比较角色\tComp\tComitative\t他成绩比我好 (他 --> 我)\n",
    "属事角色\tBelg\tBelongings\t老赵有俩女儿 (老赵 <-- 有)\n",
    "类事角色\tClas\tClassification\t他是中学生 (是 --> 中学生)\n",
    "依据角色\tAccd\tAccording\t本庭依法宣判 (依法 <-- 宣判)\n",
    "缘故角色\tReas\tReason\t他在愁女儿婚事 (愁 --> 婚事)\n",
    "意图角色\tInt\tIntention\t为了金牌他拼命努力 (金牌 <-- 努力)\n",
    "结局角色\tCons\tConsequence\t他跑了满头大汗 (跑 --> 满头大汗)\n",
    "方式角色\tMann\tManner\t球慢慢滚进空门 (慢慢 <-- 滚)\n",
    "工具角色\tTool\tTool\t她用砂锅熬粥 (砂锅 <-- 熬粥)\n",
    "材料角色\tMalt\tMaterial\t她用小米熬粥 (小米 <-- 熬粥)\n",
    "时间角色\tTime\tTime\t唐朝有个李白 (唐朝 <-- 有)\n",
    "空间角色\tLoc\tLocation\t这房子朝南 (朝 --> 南)\n",
    "历程角色\tProc\tProcess\t火车正在过长江大桥 (过 --> 大桥)\n",
    "趋向角色\tDir\tDirection\t部队奔向南方 (奔 --> 南)\n",
    "范围角色\tSco\tScope\t产品应该比质量 (比 --> 质量)\n",
    "数量角色\tQuan\tQuantity\t一年有365天 (有 --> 天)\n",
    "数量数组\tQp\tQuantity-phrase\t三本书 (三 --> 本)\n",
    "频率角色\tFreq\tFrequency\t他每天看书 (每天 <-- 看)\n",
    "顺序角色\tSeq\tSequence\t他跑第一 (跑 --> 第一)\n",
    "描写角色\tDesc(Feat)\tDescription\t他长得胖 (长 --> 胖)\n",
    "宿主角色\tHost\tHost\t住房面积 (住房 <-- 面积)\n",
    "名字修饰角色\tNmod\tName-modifier\t果戈里大街 (果戈里 <-- 大街)\n",
    "时间修饰角色\tTmod\tTime-modifier\t星期一上午 (星期一 <-- 上午)\n",
    "反角色\tr + main role\t\t打篮球的小姑娘 (打篮球 <-- 姑娘)\n",
    "嵌套角色\td + main role\t\t爷爷看见孙子在跑 (看见 --> 跑)\n",
    "并列关系\teCoo\tevent Coordination\t我喜欢唱歌和跳舞 (唱歌 --> 跳舞)\n",
    "选择关系\teSelt\tevent Selection\t您是喝茶还是喝咖啡 (茶 --> 咖啡)\n",
    "等同关系\teEqu\tevent Equivalent\t他们三个人一起走 (他们 --> 三个人)\n",
    "先行关系\tePrec\tevent Precedent\t首先，先\n",
    "顺承关系\teSucc\tevent Successor\t随后，然后\n",
    "递进关系\teProg\tevent Progression\t况且，并且\n",
    "转折关系\teAdvt\tevent adversative\t却，然而\n",
    "原因关系\teCau\tevent Cause\t因为，既然\n",
    "结果关系\teResu\tevent Result\t因此，以致\n",
    "推论关系\teInf\tevent Inference\t才，则\n",
    "条件关系\teCond\tevent Condition\t只要，除非\n",
    "假设关系\teSupp\tevent Supposition\t如果，要是\n",
    "让步关系\teConc\tevent Concession\t纵使，哪怕\n",
    "手段关系\teMetd\tevent Method\t\n",
    "目的关系\tePurp\tevent Purpose\t为了，以便\n",
    "割舍关系\teAban\tevent Abandonment\t与其，也不\n",
    "选取关系\tePref\tevent Preference\t不如，宁愿\n",
    "总括关系\teSum\tevent Summary\t总而言之\n",
    "分叙关系\teRect\tevent Recount\t例如，比方说\n",
    "连词标记\tmConj\tRecount Marker\t和，或\n",
    "的字标记\tmAux\tAuxiliary\t的，地，得\n",
    "介词标记\tmPrep\tPreposition\t把，被\n",
    "语气标记\tmTone\tTone\t吗，呢\n",
    "时间标记\tmTime\tTime\t才，曾经\n",
    "范围标记\tmRang\tRange\t都，到处\n",
    "程度标记\tmDegr\tDegree\t很，稍微\n",
    "频率标记\tmFreq\tFrequency Marker\t再，常常\n",
    "趋向标记\tmDir\tDirection Marker\t上去，下来\n",
    "插入语标记\tmPars\tParenthesis Marker\t总的来说，众所周知\n",
    "否定标记\tmNeg\tNegation Marker\t不，没，未\n",
    "情态标记\tmMod\tModal Marker\t幸亏，会，能\n",
    "标点标记\tmPunc\tPunctuation Marker\t，。！\n",
    "重复标记\tmPept\tRepetition Marker\t走啊走 (走 --> 走)\n",
    "多数标记\tmMaj\tMajority Marker\t们，等\n",
    "实词虚化标记\tmVain\tVain Marker\t\n",
    "离合标记\tmSepa\tSeperation Marker\t吃了个饭 (吃 --> 饭) 洗了个澡 (洗 --> 澡)\n",
    "根节点\tRoot\tRoot\t全句核心节点\n",
    "\n",
    "## 机器翻译\n",
    "我们的翻译机器就是其中带有问号的黑箱，它的作用就是能够将一个语言的序列（如Economic growth has slowed down in recent years）转化成目标语言序列（如La croissance economique sest ralentie ces dernieres annees）。其中翻译机器在正式工作之前可以利用已有的语料库（Corpora）来进行学习和训练。所谓的神经网络机器翻译就是利用神经网络来实现上述的黑箱翻译机器。\n",
    "编码解码框架（2014年中期提出）\n",
    "注意力机制（2014年末提出）\n",
    "外存（2015年新星）\n",
    "残差网络（2015年新星）\n",
    "其它辅助手段（2016年新技术\n",
    "\n",
    "## 人机对话系统\n",
    "人机对话系统\n",
    "    闲聊系统：开放域\n",
    "    知识问答：开放域知识获取\n",
    "    任务执行：特定域完成任务或动作\n",
    "    推荐：特定域信息推荐\n",
    "实用技术：\n",
    "    语言理解：序列标注----》深度学习\n",
    "    对话管理：基于规则---》基于有指导学习---》强化学习\n",
    "    对话生成：基于模板---》语言模型---》Seq2Seq\n",
    "    多轮对话：重排序模型---》层次化模型---》DQN模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.book import *\n",
    "text1#可以显示text1中的文本\n",
    "text1.concordance(\"monstrous\")\n",
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text2.common_contexts([\"monstrous\",\"very\"])\n",
    "text4.dispersion_plot([\"citizens\",\"democracy\",\"freedom\",\"duties\",\"America\"])\n",
    "len(text3)\n",
    "sorted(set(text3))\n",
    "len(text3)/len(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义函数\n",
    "def divlen(text):\n",
    "    return len(text)/len(set(text))\n",
    "divlen(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#词表基本操作\n",
    "let1=['you','shi','shui','?']\n",
    "let2=['me','shi','sha','*','.']\n",
    "let1+let2\n",
    "let1.append(let2)\n",
    "let1\n",
    "text4[64]\n",
    "text4.index('voice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#切片操作\n",
    "let1[:2]\n",
    "let1[1:]\n",
    "let1[0:3]\n",
    "#通过切片来替换元素\n",
    "let3=['0','1','2','3','4','5','6','7']\n",
    "let3[1:3]='x'\n",
    "let3\n",
    "num=let3[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#字符串加法和乘法\n",
    "name1='bili'\n",
    "name2='tuoku'\n",
    "name3=name1*2\n",
    "name4=name1*2+' '+name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#词频绘图\n",
    "fre=FreqDist(text1)\n",
    "fre\n",
    "fre.keys\n",
    "fre.plot(50,cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#根据特征选择词\n",
    "V=set(text1)\n",
    "long_words=[w for w in V if len(w)>15]\n",
    "fred=FreqDist(text1)\n",
    "long_fre_words=[w for w in V if len(w)>7 and fred[w]>7]\n",
    "long_fre_words\n",
    "fred.items\n",
    "fred.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#循环条件判断\n",
    "for word in let2:\n",
    "    if word.endswith('i'):\n",
    "        print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
